{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('python38': conda)"
  },
  "interpreter": {
   "hash": "3d6ccd2bcfab28fb4b08948d903be8a3077fc288a2616d4055f0b5a296f9cf65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import os.path\r\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def errorfill(x, y, yerr, color=None, alpha_fill=0.1, ax=None, linestyle=None):\r\n",
    "    ax = ax if ax is not None else plt.gca()\r\n",
    "    if color is None:\r\n",
    "        color = ax._get_lines.color_cycle.next()\r\n",
    "    if np.isscalar(yerr) or len(yerr) == len(y):\r\n",
    "        ymin = y - yerr\r\n",
    "        ymax = y + yerr\r\n",
    "        ind_min = np.where(ymin<0)\r\n",
    "        ind_max = np.where(ymax>1)\r\n",
    "        ymax[ind_max] = 1.0\r\n",
    "        ymin[ind_min] = 0.0\r\n",
    "    elif len(yerr) == 2:\r\n",
    "        ymin, ymax = yerr\r\n",
    "    ax.plot(x, y, color=color, linestyle=linestyle)\r\n",
    "    ax.fill_between(x, ymax, ymin, color=color, alpha=alpha_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DM3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenario = 'dm3'\r\n",
    "tasks = ['dbpedia_dnb','dbpedia_viaf','abt_buy','amazon_google','wdc_watches','wdc_cameras','wdc_phones','wdc_headphones']\r\n",
    "\r\n",
    "for task in tasks:\r\n",
    "\r\n",
    "    if task == 'dbpedia_viaf':\r\n",
    "        passive_learning = [0.954]\r\n",
    "        pl2000 = [0.851]\r\n",
    "        pl1000 = [0.804]\r\n",
    "        ylim = (0.2,1)\r\n",
    "    if task == 'dbpedia_dnb':\r\n",
    "        passive_learning = [0.92]\r\n",
    "        pl2000 = [0.779]\r\n",
    "        pl1000 = [0.700]\r\n",
    "        ylim = (0.2,1)\r\n",
    "    if task == 'abt_buy':\r\n",
    "        passive_learning = [0.667]\r\n",
    "        pl2000 = [0.496]\r\n",
    "        pl1000 = [0.345]\r\n",
    "        ylim = (0.1,0.8)\r\n",
    "    if task == 'amazon_google':\r\n",
    "        passive_learning = [0.733]\r\n",
    "        pl2000 = [0.558]\r\n",
    "        pl1000 = [0.442]\r\n",
    "        ylim = (0,0.8)\r\n",
    "    if task == 'wdc_cameras':\r\n",
    "        passive_learning = [0.746]\r\n",
    "        pl2000 = [0.653]\r\n",
    "        pl1000 = [0.621]\r\n",
    "        ylim = (0.4,0.9)\r\n",
    "    if task == 'wdc_watches':\r\n",
    "        passive_learning = [0.917]\r\n",
    "        pl2000 = [0.529]\r\n",
    "        pl1000 = [0.448]\r\n",
    "        ylim = (0.2,1)\r\n",
    "    if task == 'wdc_phones':\r\n",
    "        passive_learning = [0.922]\r\n",
    "        pl2000 = [0.69]\r\n",
    "        pl1000 = [0.513]\r\n",
    "        ylim = (0,1)\r\n",
    "    if task == 'wdc_headphones':\r\n",
    "        passive_learning = [0.914]\r\n",
    "        pl2000 = [0.778]\r\n",
    "        pl1000 = [0.530]\r\n",
    "        ylim = (0.2,1)\r\n",
    "\r\n",
    "\r\n",
    "    al_random_init = pd.read_csv(os.path.join(scenario,task,'al_random_init_'+task+'.csv'))\r\n",
    "    al_tl = pd.read_csv(os.path.join(scenario,task,'al_tl_'+task+'.csv'))\r\n",
    "    al_tl_da = pd.read_csv(os.path.join(scenario,task,'al_tl_da_'+task+'.csv'))\r\n",
    "    al_tl_include_source = pd.read_csv(os.path.join(scenario,task,'al_tl_include_source_'+task+'.csv'))\r\n",
    "    #al_tl_da_to_ls = pd.read_csv(os.path.join(scenario,task,'al_tl_da_to_ls_'+task+'.csv'))\r\n",
    "    #al_tl_da_thresh = pd.read_csv(os.path.join(scenario,task,'al_tl_da_thresh_'+task+'.csv'))\r\n",
    "\r\n",
    "    query_num = np.arange(0,2100,100)\r\n",
    "    if task in ['wdc_phones','wdc_headphones']:\r\n",
    "        query_num = np.arange(0,220,20)\r\n",
    "    if task in ['wdc_watches']:\r\n",
    "        query_num = np.arange(0,4100,100)\r\n",
    "\r\n",
    "    #query_num = np.arange(0,len(al_random_init['F1 Mean']))\r\n",
    "\r\n",
    "    passive_learning = passive_learning*len(al_random_init['F1 Mean'])\r\n",
    "    pl2000 = pl2000*len(al_random_init['F1 Mean'])\r\n",
    "    pl1000 = pl1000*len(al_random_init['F1 Mean'])\r\n",
    "\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "\r\n",
    "    pas_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL\")\r\n",
    "    if task in ['wdc_phones','wdc_headphones']:\r\n",
    "        pl2_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL200\", linestyle ='--')\r\n",
    "        pl1_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL100\", linestyle='dotted')\r\n",
    "    else:\r\n",
    "        pl2_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL2000\", linestyle ='--')\r\n",
    "        pl1_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL1000\", linestyle='dotted')\r\n",
    "    alrandominit_, = ax.plot(query_num, al_random_init['F1 Mean'], color=\"#D55E00\", label=\"al_random_init\", linestyle ='--')\r\n",
    "    altl_, = ax.plot(query_num, al_tl['F1 Mean'], color=\"#2F73B2\", label=\"al_tl\" , linestyle = 'dotted')\r\n",
    "    altlda_, = ax.plot(query_num, al_tl_da['F1 Mean'], color=\"#4E9E73\", label=\"al_tl_da\", linestyle='dashdot')\r\n",
    "    altlis_, = ax.plot(query_num, al_tl_include_source['F1 Mean'], color=\"#6B00D7\", label=\"al_tl_include_source\", linestyle='dotted')\r\n",
    "    #altldatols_, = ax.plot(query_num, al_tl_da_to_ls['F1 Mean'], color=\"#6B00D7\", label=\"al_tl_da_to_ls\", linestyle='dashdot')\r\n",
    "    #altldathresh_, = ax.plot(query_num, al_tl_da_thresh['F1 Mean'], color=\"#6CFF6C\", label=\"al_tl_da_thresh\", linestyle='dashdot')\r\n",
    "\r\n",
    "    ax.plot(query_num,passive_learning, color=\"#000000\")\r\n",
    "    ax.plot(query_num,pl2000, color=\"#000000\", linestyle ='--')\r\n",
    "    ax.plot(query_num,pl1000, color=\"#000000\", linestyle='dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_random_init['F1 Mean'], color=\"#D55E00\", linestyle='--')\r\n",
    "    errorfill(query_num, al_random_init['F1 Mean'].to_numpy(), al_random_init['F1 Std'].to_numpy(), color=\"#D55E00\", linestyle ='--')\r\n",
    "\r\n",
    "    #ax.plot(al_tl['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    errorfill(query_num, al_tl['F1 Mean'].to_numpy(), al_tl['F1 Std'].to_numpy(), color=\"#2F73B2\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    errorfill(query_num, al_tl_da['F1 Mean'].to_numpy(), al_tl_da['F1 Std'].to_numpy(), color=\"#4E9E73\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    errorfill(query_num, al_tl_include_source['F1 Mean'].to_numpy(), al_tl_include_source['F1 Std'].to_numpy(), color=\"#6B00D7\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da_to_ls['F1 Mean'], color=\"#6B00D7\" , linestyle = 'dotted')\r\n",
    "    #errorfill(query_num, al_tl_da_to_ls['F1 Mean'].to_numpy(), al_tl_da_to_ls['F1 Std'].to_numpy(), color=\"#6B00D7\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da_thresh['F1 Mean'], color=\"#6CFF6C\" , linestyle = 'dotted')\r\n",
    "    #errorfill(query_num, al_tl_da_thresh['F1 Mean'].to_numpy(), al_tl_da_thresh['F1 Std'].to_numpy(), color=\"#6CFF6C\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.1))\r\n",
    "    plt.ylim(ylim)\r\n",
    "\r\n",
    "    ax.grid(True)\r\n",
    "    gridlines = ax.get_xgridlines()\r\n",
    "    for line in gridlines:\r\n",
    "        line.set_linestyle('-.')\r\n",
    "    ax.set_xlabel(\"# Labeled Target Examples\", fontsize=10)\r\n",
    "    ax.set_ylabel(\"F1\", fontsize=10)\r\n",
    "\r\n",
    "    #ax.legend(handles=[pas_, alrandominit_, altl_, altlda_, altldatols_, altldathresh_], fontsize=12)\r\n",
    "    ax.legend(handles=[pas_, pl2_, pl1_, alrandominit_, altl_, altlda_, altlis_], fontsize=9, bbox_to_anchor=(1.01, 1), loc='upper left')\r\n",
    "\r\n",
    "    #plt.title(task, fontsize=12)\r\n",
    "\r\n",
    "    plt.xticks(fontsize=10)\r\n",
    "    plt.yticks(fontsize=10)\r\n",
    "\r\n",
    "    plt.savefig('%s.pdf' % (os.path.join(scenario,'graphs',task)), bbox_inches='tight', format='pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ditto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scenario = 'ditto'\r\n",
    "#tasks =\r\n",
    "#['dbpedia_dnb','dbpedia_viaf','abt_buy','amazon_google','wdc_watches','wdc_cameras','wdc_phones','wdc_headphones']\r\n",
    "#tasks = ['dbpedia_dnb','amazon_google','wdc_watches','wdc_cameras']\r\n",
    "tasks = ['dbpedia_viaf']\r\n",
    "for task in tasks:\r\n",
    "\r\n",
    "    if task == 'dbpedia_viaf':\r\n",
    "        passive_learning = [0.992]\r\n",
    "        pl2000 = [0.964]\r\n",
    "        pl1000 = [0.950]\r\n",
    "        ylim = (0.2,1)\r\n",
    "    if task == 'dbpedia_dnb':\r\n",
    "        passive_learning = [0.989]\r\n",
    "        pl2000 = [0.977]\r\n",
    "        pl1000 = [0.964]\r\n",
    "        ylim = (0.6,1)\r\n",
    "    if task == 'abt_buy':\r\n",
    "        passive_learning = [0.957]\r\n",
    "        pl2000 = [0.887]\r\n",
    "        pl1000 = [0.830]\r\n",
    "        ylim = (0.1,1)\r\n",
    "    if task == 'amazon_google':\r\n",
    "        passive_learning = [0.821]\r\n",
    "        pl2000 = [0.801]\r\n",
    "        pl1000 = [0.721]\r\n",
    "        ylim = (0.1,1)\r\n",
    "    if task == 'wdc_cameras':\r\n",
    "        passive_learning = [0.901]\r\n",
    "        pl2000 = [0.849]\r\n",
    "        pl1000 = [0.808]\r\n",
    "        ylim = (0.3,1)\r\n",
    "    if task == 'wdc_watches':\r\n",
    "        passive_learning = [0.969]\r\n",
    "        pl2000 = [0.864]\r\n",
    "        pl1000 = [0.749]\r\n",
    "        ylim = (0.2,1)\r\n",
    "    #if task == 'wdc_phones':\r\n",
    "    #    passive_learning = [0.919]\r\n",
    "    #    pl2000 = [0.69]\r\n",
    "    #    pl1000 = [0.513]\r\n",
    "    #    ylim = (0,1)\r\n",
    "    #if task == 'wdc_headphones':\r\n",
    "    #    passive_learning = [0.963]\r\n",
    "    #    pl2000 = [0.778]\r\n",
    "    #    pl1000 = [0.530]\r\n",
    "    #    ylim = (0.2,1)\r\n",
    "\r\n",
    "\r\n",
    "    al_random_init = pd.read_csv(os.path.join(scenario,task,'al_random_init_'+task+'.csv'))\r\n",
    "    al_tl = pd.read_csv(os.path.join(scenario,task,'al_tl_'+task+'.csv'))\r\n",
    "    #al_tl_da = pd.read_csv(os.path.join(scenario,task,'al_tl_da_'+task+'.csv'))\r\n",
    "    al_tl_include_source = pd.read_csv(os.path.join(scenario,task,'al_tl_include_source_'+task+'.csv'))\r\n",
    "    #al_tl_da_to_ls = pd.read_csv(os.path.join(scenario,task,'al_tl_da_to_ls_'+task+'.csv'))\r\n",
    "    #al_tl_da_thresh = pd.read_csv(os.path.join(scenario,task,'al_tl_da_thresh_'+task+'.csv'))\r\n",
    "\r\n",
    "    query_num = np.arange(0,2100,100)\r\n",
    "    if task in ['wdc_phones','wdc_headphones']:\r\n",
    "        query_num = np.arange(0,220,20)\r\n",
    "    if task in ['wdc_watches']:\r\n",
    "        query_num = np.arange(0,4200,200)\r\n",
    "\r\n",
    "    #query_num = np.arange(0,len(al_random_init['F1 Mean']))\r\n",
    "\r\n",
    "    passive_learning = passive_learning*len(al_random_init['F1 Mean'])\r\n",
    "    pl2000 = pl2000*len(al_random_init['F1 Mean'])\r\n",
    "    pl1000 = pl1000*len(al_random_init['F1 Mean'])\r\n",
    "\r\n",
    "    fig, ax = plt.subplots()\r\n",
    "\r\n",
    "    pas_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL\")\r\n",
    "    if task in ['wdc_phones','wdc_headphones']:\r\n",
    "        pl2_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL200\", linestyle ='--')\r\n",
    "        pl1_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL100\", linestyle='dotted')\r\n",
    "    else:\r\n",
    "        pl2_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL2000\", linestyle ='--')\r\n",
    "        pl1_, =  ax.plot(query_num, passive_learning, color=\"#000000\", label=\"PL1000\", linestyle='dotted')\r\n",
    "    alrandominit_, = ax.plot(query_num, al_random_init['F1 Mean'], color=\"#D55E00\", label=\"al_random_init\", linestyle ='--')\r\n",
    "    altl_, = ax.plot(query_num, al_tl['F1 Mean'], color=\"#2F73B2\", label=\"al_tl\" , linestyle = 'dotted')\r\n",
    "    #altlda_, = ax.plot(query_num, al_tl_da['F1 Mean'], color=\"#4E9E73\", label=\"al_tl_da\", linestyle='dashdot')\r\n",
    "    altlis_, = ax.plot(query_num, al_tl_include_source['F1 Mean'], color=\"#6B00D7\", label=\"al_tl_include_source\", linestyle='dotted')\r\n",
    "    #altldatols_, = ax.plot(query_num, al_tl_da_to_ls['F1 Mean'], color=\"#6B00D7\", label=\"al_tl_da_to_ls\", linestyle='dashdot')\r\n",
    "    #altldathresh_, = ax.plot(query_num, al_tl_da_thresh['F1 Mean'], color=\"#6CFF6C\", label=\"al_tl_da_thresh\", linestyle='dashdot')\r\n",
    "\r\n",
    "    ax.plot(query_num,passive_learning, color=\"#000000\")\r\n",
    "    ax.plot(query_num,pl2000, color=\"#000000\", linestyle ='--')\r\n",
    "    ax.plot(query_num,pl1000, color=\"#000000\", linestyle='dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_random_init['F1 Mean'], color=\"#D55E00\", linestyle='--')\r\n",
    "    errorfill(query_num, al_random_init['F1 Mean'].to_numpy(), al_random_init['F1 Std'].to_numpy(), color=\"#D55E00\", linestyle ='--')\r\n",
    "\r\n",
    "    #ax.plot(al_tl['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    errorfill(query_num, al_tl['F1 Mean'].to_numpy(), al_tl['F1 Std'].to_numpy(), color=\"#2F73B2\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    #errorfill(query_num, al_tl_da['F1 Mean'].to_numpy(), al_tl_da['F1 Std'].to_numpy(), color=\"#4E9E73\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da['F1 Mean'], color=\"#2F73B2\" , linestyle = 'dotted')\r\n",
    "    errorfill(query_num, al_tl_include_source['F1 Mean'].to_numpy(), al_tl_include_source['F1 Std'].to_numpy(), color=\"#6B00D7\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da_to_ls['F1 Mean'], color=\"#6B00D7\" , linestyle = 'dotted')\r\n",
    "    #errorfill(query_num, al_tl_da_to_ls['F1 Mean'].to_numpy(), al_tl_da_to_ls['F1 Std'].to_numpy(), color=\"#6B00D7\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    #ax.plot(al_tl_da_thresh['F1 Mean'], color=\"#6CFF6C\" , linestyle = 'dotted')\r\n",
    "    #errorfill(query_num, al_tl_da_thresh['F1 Mean'].to_numpy(), al_tl_da_thresh['F1 Std'].to_numpy(), color=\"#6CFF6C\", linestyle = 'dotted')\r\n",
    "\r\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.1))\r\n",
    "    plt.ylim(ylim)\r\n",
    "\r\n",
    "    ax.grid(True)\r\n",
    "    gridlines = ax.get_xgridlines()\r\n",
    "    for line in gridlines:\r\n",
    "        line.set_linestyle('-.')\r\n",
    "    ax.set_xlabel(\"# Labeled Target Examples\", fontsize=10)\r\n",
    "    ax.set_ylabel(\"F1\", fontsize=10)\r\n",
    "\r\n",
    "    #ax.legend(handles=[pas_, alrandominit_, altl_, altlda_, altldatols_, altldathresh_], fontsize=12)\r\n",
    "    ax.legend(handles=[pas_, pl2_, pl1_, alrandominit_, altl_, altlis_], fontsize=9, bbox_to_anchor=(1.01, 1), loc='upper left')\r\n",
    "\r\n",
    "    #plt.title(task, fontsize=12)\r\n",
    "\r\n",
    "    plt.xticks(fontsize=10)\r\n",
    "    plt.yticks(fontsize=10)\r\n",
    "\r\n",
    "    plt.savefig('%s.pdf' % (os.path.join(scenario,'graphs',task)), bbox_inches='tight', format='pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot data augmentation labels\r\n",
    "df_da = pd.read_csv(os.path.join('final/deepmatcher','amazon_google','al_tl_da_amazon_google.csv'))\r\n",
    "import json\r\n",
    "mean_cm = df_da.apply(lambda x: [round(val/3) for val in [sum(a) for a in zip(json.loads(x['Run 1: da labels']), json.loads(x['Run 2: da labels']), json.loads(x['Run 3: da labels']))]],axis=1)\r\n",
    "print(pd.DataFrame.from_dict(dict(zip(mean_cm.index, mean_cm.values))).to_latex(index=False))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}